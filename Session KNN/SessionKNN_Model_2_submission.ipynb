{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "70418e65",
   "metadata": {
    "id": "2ea29670"
   },
   "source": [
    "# Impementing the Session KNN Algo on the Coveo Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97ea9bb4",
   "metadata": {
    "id": "dde053f3"
   },
   "source": [
    "### Import libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b78d5cb",
   "metadata": {
    "id": "1250aeb0"
   },
   "outputs": [],
   "source": [
    "#import libraries \n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import seaborn as sns \n",
    "import matplotlib.pyplot as plt \n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d7cdf01",
   "metadata": {
    "id": "d4737b9a"
   },
   "outputs": [],
   "source": [
    "#import other lib \n",
    "import os \n",
    "import time\n",
    "import datetime \n",
    "from tqdm import tqdm \n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daf303cb",
   "metadata": {
    "id": "ea16e322"
   },
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01808596",
   "metadata": {
    "id": "OvvRfsBF8Y6F"
   },
   "outputs": [],
   "source": [
    "Path1 = '/content/drive/MyDrive/Colab Notebooks/KNN Model/knn_train_data.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ff11405",
   "metadata": {
    "id": "qFSCmTgc8YvV"
   },
   "outputs": [],
   "source": [
    "Path2 = '/content/drive/MyDrive/Colab Notebooks/KNN Model/knn_test_data.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00f22831",
   "metadata": {
    "id": "2c5a12ce"
   },
   "outputs": [],
   "source": [
    "#load train daa \n",
    "\n",
    "training_data = pd.read_csv('knn_train_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25817e17",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "868418c3",
    "outputId": "70ac2b53-62c9-4f24-cdcf-0f4853728a80"
   },
   "outputs": [],
   "source": [
    "training_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b85423a4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2672cc18",
    "outputId": "ad9dfd0f-34bc-4656-ce32-df44079d2d66"
   },
   "outputs": [],
   "source": [
    "print(training_data.info())\n",
    "print('------------------')\n",
    "print(training_data.nunique())\n",
    "print('------------------')\n",
    "print(training_data.isnull().sum())\n",
    "print('------------------')\n",
    "print(training_data.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6375f2a",
   "metadata": {
    "id": "9bb7a8a1"
   },
   "outputs": [],
   "source": [
    "#load test_data\n",
    "\n",
    "test_data = pd.read_csv('knn_test_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ba310f9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "92bdf63b",
    "outputId": "b31114c4-6528-4f4b-cbfd-bf7c59843c17"
   },
   "outputs": [],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41414194",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0ad53b27",
    "outputId": "9611e4be-86b0-4bce-b1dd-2147f5780027"
   },
   "outputs": [],
   "source": [
    "print(test_data.info())\n",
    "print('------------------')\n",
    "print(test_data.nunique())\n",
    "print('------------------')\n",
    "print(test_data.isnull().sum())\n",
    "print('------------------')\n",
    "print(test_data.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a6bb9fc",
   "metadata": {
    "id": "3ed79660"
   },
   "outputs": [],
   "source": [
    "def create_seq_db_filter_top_k( data, topk=0):\n",
    "    \n",
    "\n",
    "    c = Counter(list(data['item_id']))\n",
    "\n",
    "    if topk > 1:\n",
    "        keeper = set([x[0] for x in c.most_common(topk)])\n",
    "        data = data[data['item_id'].isin(keeper)]\n",
    "\n",
    "    # group by session id and concat song_id\n",
    "    groups = data.groupby('session_id')\n",
    "\n",
    "    # convert item ids to string, then aggregate them to lists\n",
    "    aggregated = groups['item_id'].agg(**{'sequence': lambda x: list(map(str, x))})\n",
    "    init_ts = groups['ts'].min()\n",
    "    \n",
    "\n",
    "    result = aggregated.join(init_ts)\n",
    "    result.reset_index(inplace=True)\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be4f6f78",
   "metadata": {
    "id": "e7bfb154"
   },
   "outputs": [],
   "source": [
    "training_data = create_seq_db_filter_top_k(training_data, topk=0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5bc547b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "1932ea41",
    "outputId": "2cc628d5-6656-42ab-bf2d-da9e133f76f1"
   },
   "outputs": [],
   "source": [
    "training_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cb7dd79",
   "metadata": {
    "id": "21355a8f"
   },
   "outputs": [],
   "source": [
    "test_data = create_seq_db_filter_top_k(test_data, topk=0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd93ea70",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "a13fc906",
    "outputId": "922ed56d-4221-4464-be73-dde93c38e7d5"
   },
   "outputs": [],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20dc3493",
   "metadata": {
    "id": "9fb56764"
   },
   "outputs": [],
   "source": [
    "#initiate conter \n",
    "# cnt the sequence \n",
    "\n",
    "train_cnt = Counter()\n",
    "training_data.sequence.map(train_cnt.update);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8209e4a8",
   "metadata": {
    "id": "d5605aa2"
   },
   "outputs": [],
   "source": [
    "# find the most common 5 items\n",
    "print('Most popular items: {}'.format(train_cnt.most_common(2000)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca093536",
   "metadata": {
    "id": "695e0a3c"
   },
   "outputs": [],
   "source": [
    "#initiate conter \n",
    "# cnt the sequence \n",
    "\n",
    "test_cnt = Counter()\n",
    "test_data.sequence.map(test_cnt.update);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53f5e02f",
   "metadata": {
    "id": "4ba0bb76"
   },
   "outputs": [],
   "source": [
    "# find the most common 5 items\n",
    "print('Most popular items: {}'.format(test_cnt.most_common(2000)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "053efc5a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0060859c",
    "outputId": "ec3a6483-c765-45fa-a945-89f5a8afa647"
   },
   "outputs": [],
   "source": [
    "print(training_data.session_id.nunique())\n",
    "print(test_data.session_id.nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af83081c",
   "metadata": {
    "id": "8f4bd283"
   },
   "outputs": [],
   "source": [
    "train_sequence_length = training_data.sequence.map(len).values\n",
    "\n",
    "print('\\nTrain Session length:\\n\\tAverage: {:.2f}\\n\\tMedian: {}\\n\\tMin: {}\\n\\tMax: {}'.format(\n",
    "    train_sequence_length.mean(), \n",
    "    np.quantile(train_sequence_length, 0.5), \n",
    "    train_sequence_length.min(), \n",
    "    train_sequence_length.max()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f8afa53",
   "metadata": {
    "id": "149a2230"
   },
   "outputs": [],
   "source": [
    "test_sequence_length = test_data.sequence.map(len).values\n",
    "\n",
    "print('\\nTest Session length:\\n\\tAverage: {:.2f}\\n\\tMedian: {}\\n\\tMin: {}\\n\\tMax: {}'.format(\n",
    "    test_sequence_length.mean(), \n",
    "    np.quantile(test_sequence_length, 0.5), \n",
    "    test_sequence_length.min(), \n",
    "    test_sequence_length.max()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c26e6f79",
   "metadata": {
    "id": "4c33a8ec"
   },
   "source": [
    "### Recommendation Model - Session KNN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9dabc2a",
   "metadata": {
    "id": "eef173fa"
   },
   "outputs": [],
   "source": [
    "from _operator import itemgetter\n",
    "from math import sqrt\n",
    "import random\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa188aa9",
   "metadata": {
    "id": "85294af1"
   },
   "outputs": [],
   "source": [
    "class SessionKNN:\n",
    "\n",
    "\n",
    "    def __init__(self, k, sample_size=1000, sampling='recent', similarity='cosine', remind=False, pop_boost=0,\n",
    "                 extend=False, normalize=True, session_key='SessionId', item_key='ItemId', time_key='Time'):\n",
    "\n",
    "        self.remind = remind\n",
    "        self.k = k\n",
    "        self.sample_size = sample_size\n",
    "        self.sampling = sampling\n",
    "        self.similarity = similarity\n",
    "        self.pop_boost = pop_boost\n",
    "        self.session_key = session_key\n",
    "        self.item_key = item_key\n",
    "        self.time_key = time_key\n",
    "        self.extend = extend\n",
    "        self.normalize = normalize\n",
    "\n",
    "        # updated while recommending\n",
    "        self.session = -1\n",
    "        self.session_items = []\n",
    "        self.relevant_sessions = set()\n",
    "\n",
    "        # cache relations once at startup\n",
    "        self.session_item_map = dict()\n",
    "        self.item_session_map = dict()\n",
    "        self.session_time = dict()\n",
    "\n",
    "        self.sim_time = 0\n",
    "\n",
    "    def fit(self, train):\n",
    "        '''\n",
    "        Trains the predictor.\n",
    "        \n",
    "        Parameters\n",
    "        --------\n",
    "        data: pandas.DataFrame\n",
    "            Training data. It contains the transactions of the sessions. It has one column for session IDs, one for item IDs and one for the timestamp of the events (unix timestamps).\n",
    "            It must have a header. Column names are arbitrary, but must correspond to the ones you set during the initialization of the network (session_key, item_key, time_key properties).\n",
    "            \n",
    "        '''\n",
    "\n",
    "        index_session = train.columns.get_loc(self.session_key)\n",
    "        index_item = train.columns.get_loc(self.item_key)\n",
    "        index_time = train.columns.get_loc(self.time_key)\n",
    "        self.itemids = train[self.item_key].unique()\n",
    "\n",
    "        session = -1\n",
    "        session_items = set()\n",
    "        time = -1\n",
    "        # cnt = 0\n",
    "        for row in train.itertuples(index=False):\n",
    "            # cache items of sessions\n",
    "            if row[index_session] != session:\n",
    "                if len(session_items) > 0:\n",
    "                    self.session_item_map.update({session: session_items})\n",
    "                    # cache the last time stamp of the session\n",
    "                    self.session_time.update({session: time})\n",
    "                session = row[index_session]\n",
    "                session_items = set()\n",
    "            time = row[index_time]\n",
    "            session_items.add(row[index_item])\n",
    "\n",
    "            # cache sessions involving an item\n",
    "            map_is = self.item_session_map.get(row[index_item])\n",
    "            if map_is is None:\n",
    "                map_is = set()\n",
    "                self.item_session_map.update({row[index_item]: map_is})\n",
    "            map_is.add(row[index_session])\n",
    "\n",
    "        # Add the last tuple    \n",
    "        self.session_item_map.update({session: session_items})\n",
    "        self.session_time.update({session: time})\n",
    "\n",
    "    def predict_next(self, session_id, input_item_id, predict_for_item_ids=None, skip=False, type='view', timestamp=0):\n",
    "        '''\n",
    "        Gives predicton scores for a selected set of items on how likely they be the next item in the session.\n",
    "                \n",
    "        Parameters\n",
    "        --------\n",
    "        session_id : int or string\n",
    "            The session IDs of the event.\n",
    "        input_item_id : int or string\n",
    "            The item ID of the event. Must be in the set of item IDs of the training set.\n",
    "        predict_for_item_ids : 1D array\n",
    "            IDs of items for which the network should give prediction scores. Every ID must be in the set of item IDs of the training set.\n",
    "            \n",
    "        Returns\n",
    "        --------\n",
    "        out : pandas.Series\n",
    "            Prediction scores for selected items on how likely to be the next item of this session. Indexed by the item IDs.\n",
    "        \n",
    "        '''\n",
    "\n",
    "        #         gc.collect()\n",
    "        #         process = psutil.Process(os.getpid())\n",
    "        #         print( 'cknn.predict_next: ', process.memory_info().rss, ' memory used')\n",
    "\n",
    "        if (self.session != session_id):  # new session\n",
    "\n",
    "            if (self.extend):\n",
    "                item_set = set(self.session_items)\n",
    "                self.session_item_map[self.session] = item_set;\n",
    "                for item in item_set:\n",
    "                    map_is = self.item_session_map.get(item)\n",
    "                    if map_is is None:\n",
    "                        map_is = set()\n",
    "                        self.item_session_map.update({item: map_is})\n",
    "                    map_is.add(self.session)\n",
    "\n",
    "                ts = time.time()\n",
    "                self.session_time.update({self.session: ts})\n",
    "\n",
    "            self.session = session_id\n",
    "            self.session_items = list()\n",
    "            self.relevant_sessions = set()\n",
    "\n",
    "        if type == 'view':\n",
    "            self.session_items.append(input_item_id)\n",
    "\n",
    "        if skip:\n",
    "            return\n",
    "\n",
    "        neighbors = self.find_neighbors(set(self.session_items), input_item_id, session_id)\n",
    "        scores = self.score_items(neighbors)\n",
    "\n",
    "        # add some reminders\n",
    "        if self.remind:\n",
    "\n",
    "            reminderScore = 5\n",
    "            takeLastN = 3\n",
    "\n",
    "            cnt = 0\n",
    "            for elem in self.session_items[-takeLastN:]:\n",
    "                cnt = cnt + 1\n",
    "                # reminderScore = reminderScore + (cnt/100)\n",
    "\n",
    "                oldScore = scores.get(elem)\n",
    "                newScore = 0\n",
    "                if oldScore is None:\n",
    "                    newScore = reminderScore\n",
    "                else:\n",
    "                    newScore = oldScore + reminderScore\n",
    "                # print 'old score ', oldScore\n",
    "                # update the score and add a small number for the position \n",
    "                newScore = (newScore * reminderScore) + (cnt / 100)\n",
    "\n",
    "                scores.update({elem: newScore})\n",
    "\n",
    "        # push popular ones\n",
    "        if self.pop_boost > 0:\n",
    "\n",
    "            pop = self.item_pop(neighbors)\n",
    "            # Iterate over the item neighbors\n",
    "            # print itemScores\n",
    "            for key in scores:\n",
    "                item_pop = pop.get(key)\n",
    "                # Gives some minimal MRR boost?\n",
    "                scores.update({key: (scores[key] + (self.pop_boost * item_pop))})\n",
    "\n",
    "        # Create things in the format ..\n",
    "        if predict_for_item_ids is None:\n",
    "            predict_for_item_ids = self.itemids\n",
    "        predictions = np.zeros(len(predict_for_item_ids))\n",
    "        mask = np.in1d(predict_for_item_ids, list(scores.keys()))\n",
    "\n",
    "        items = predict_for_item_ids[mask]\n",
    "        values = [scores[x] for x in items]\n",
    "        predictions[mask] = values\n",
    "        series = pd.Series(data=predictions, index=predict_for_item_ids)\n",
    "\n",
    "        if self.normalize:\n",
    "            series = series / series.max()\n",
    "\n",
    "        return series\n",
    "\n",
    "    def item_pop(self, sessions):\n",
    "        '''\n",
    "        Returns a dict(item,score) of the item popularity for the given list of sessions (only a set of ids)\n",
    "        \n",
    "        Parameters\n",
    "        --------\n",
    "        sessions: set\n",
    "        \n",
    "        Returns\n",
    "        --------\n",
    "        out : dict            \n",
    "        '''\n",
    "        result = dict()\n",
    "        max_pop = 0\n",
    "        for session, weight in sessions:\n",
    "            items = self.items_for_session(session)\n",
    "            for item in items:\n",
    "\n",
    "                count = result.get(item)\n",
    "                if count is None:\n",
    "                    result.update({item: 1})\n",
    "                else:\n",
    "                    result.update({item: count + 1})\n",
    "\n",
    "                if (result.get(item) > max_pop):\n",
    "                    max_pop = result.get(item)\n",
    "\n",
    "        for key in result:\n",
    "            result.update({key: (result[key] / max_pop)})\n",
    "\n",
    "        return result\n",
    "\n",
    "    def cosine(self, first, second):\n",
    "        '''\n",
    "        Calculates the cosine similarity for two sessions\n",
    "        \n",
    "        Parameters\n",
    "        --------\n",
    "        first: Id of a session\n",
    "        second: Id of a session\n",
    "        \n",
    "        Returns \n",
    "        --------\n",
    "        out : float value           \n",
    "        '''\n",
    "        li = len(first & second)\n",
    "        la = len(first)\n",
    "        lb = len(second)\n",
    "        result = li / sqrt(la) * sqrt(lb)\n",
    "\n",
    "        return result\n",
    "\n",
    "\n",
    "    def random(self, first, second):\n",
    "        '''\n",
    "        Calculates the ? for 2 sessions\n",
    "        \n",
    "        Parameters\n",
    "        --------\n",
    "        first: Id of a session\n",
    "        second: Id of a session\n",
    "        \n",
    "        Returns \n",
    "        --------\n",
    "        out : float value           \n",
    "        '''\n",
    "        return random.random()\n",
    "\n",
    "    def items_for_session(self, session):\n",
    "        '''\n",
    "        Returns all items in the session\n",
    "        \n",
    "        Parameters\n",
    "        --------\n",
    "        session: Id of a session\n",
    "        \n",
    "        Returns \n",
    "        --------\n",
    "        out : set           \n",
    "        '''\n",
    "        return self.session_item_map.get(session);\n",
    "\n",
    "    def sessions_for_item(self, item_id):\n",
    "        '''\n",
    "        Returns all session for an item\n",
    "        \n",
    "        Parameters\n",
    "        --------\n",
    "        item: Id of the item session\n",
    "        \n",
    "        Returns \n",
    "        --------\n",
    "        out : set           \n",
    "        '''\n",
    "        return self.item_session_map.get(item_id)\n",
    "\n",
    "    def most_recent_sessions(self, sessions, number):\n",
    "        '''\n",
    "        Find the most recent sessions in the given set\n",
    "        \n",
    "        Parameters\n",
    "        --------\n",
    "        sessions: set of session ids\n",
    "        \n",
    "        Returns \n",
    "        --------\n",
    "        out : set           \n",
    "        '''\n",
    "        sample = set()\n",
    "\n",
    "        tuples = list()\n",
    "        for session in sessions:\n",
    "            time = self.session_time.get(session)\n",
    "            if time is None:\n",
    "                print(' EMPTY TIMESTAMP!! ', session)\n",
    "            tuples.append((session, time))\n",
    "\n",
    "        tuples = sorted(tuples, key=itemgetter(1), reverse=True)\n",
    "        # print 'sorted list ', sortedList\n",
    "        cnt = 0\n",
    "        for element in tuples:\n",
    "            cnt = cnt + 1\n",
    "            if cnt > number:\n",
    "                break\n",
    "            sample.add(element[0])\n",
    "        # print 'returning sample of size ', len(sample)\n",
    "        return sample\n",
    "\n",
    "    def possible_neighbor_sessions(self, session_items, input_item_id, session_id):\n",
    "        '''\n",
    "        Find a set of session to later on find neighbors in.\n",
    "        A self.sample_size of 0 uses all sessions in which any item of the current session appears.\n",
    "        self.sampling can be performed with the options \"recent\" or \"random\".\n",
    "        \"recent\" selects the self.sample_size most recent sessions while \"random\" just choses randomly. \n",
    "        \n",
    "        Parameters\n",
    "        --------\n",
    "        sessions: set of session ids\n",
    "        \n",
    "        Returns \n",
    "        --------\n",
    "        out : set           \n",
    "        '''\n",
    "\n",
    "        self.relevant_sessions = self.relevant_sessions | self.sessions_for_item(input_item_id);\n",
    "\n",
    "        if self.sample_size == 0:  # use all session as possible neighbors\n",
    "\n",
    "            print('!!!!! runnig KNN without a sample size (check config)')\n",
    "            return self.relevant_sessions\n",
    "\n",
    "        else:  # sample some sessions\n",
    "\n",
    "            self.relevant_sessions = self.relevant_sessions | self.sessions_for_item(input_item_id);\n",
    "\n",
    "            if len(self.relevant_sessions) > self.sample_size:\n",
    "\n",
    "                if self.sampling == 'recent':\n",
    "                    sample = self.most_recent_sessions(self.relevant_sessions, self.sample_size)\n",
    "                elif self.sampling == 'random':\n",
    "                    sample = random.sample(self.relevant_sessions, self.sample_size)\n",
    "                else:\n",
    "                    sample = self.relevant_sessions[:self.sample_size]\n",
    "\n",
    "                return sample\n",
    "            else:\n",
    "                return self.relevant_sessions\n",
    "\n",
    "    def calc_similarity(self, session_items, sessions):\n",
    "        '''\n",
    "        Calculates the configured similarity for the items in session_items and each session in sessions.\n",
    "        \n",
    "        Parameters\n",
    "        --------\n",
    "        session_items: set of item ids\n",
    "        sessions: list of session ids\n",
    "        \n",
    "        Returns \n",
    "        --------\n",
    "        out : list of tuple (session_id,similarity)           \n",
    "        '''\n",
    "\n",
    "        # print 'nb of sessions to test ', len(sessionsToTest), ' metric: ', self.metric\n",
    "        neighbors = []\n",
    "        cnt = 0\n",
    "        for session in sessions:\n",
    "            cnt = cnt + 1\n",
    "            # get items of the session, look up the cache first \n",
    "            session_items_test = self.items_for_session(session)\n",
    "\n",
    "            similarity = getattr(self, self.similarity)(session_items_test, session_items)\n",
    "            if similarity > 0:\n",
    "                neighbors.append((session, similarity))\n",
    "\n",
    "        return neighbors\n",
    "\n",
    "    # -----------------\n",
    "    # Find a set of neighbors, returns a list of tuples (sessionid: similarity) \n",
    "    # -----------------\n",
    "    def find_neighbors(self, session_items, input_item_id, session_id):\n",
    "        '''\n",
    "        Finds the k nearest neighbors for the given session_id and the current item input_item_id. \n",
    "        \n",
    "        Parameters\n",
    "        --------\n",
    "        session_items: set of item ids\n",
    "        input_item_id: int \n",
    "        session_id: int\n",
    "        \n",
    "        Returns \n",
    "        --------\n",
    "        out : list of tuple (session_id, similarity)           \n",
    "        '''\n",
    "        possible_neighbors = self.possible_neighbor_sessions(session_items, input_item_id, session_id)\n",
    "        possible_neighbors = self.calc_similarity(session_items, possible_neighbors)\n",
    "\n",
    "        possible_neighbors = sorted(possible_neighbors, reverse=True, key=lambda x: x[1])\n",
    "        possible_neighbors = possible_neighbors[:self.k]\n",
    "\n",
    "        return possible_neighbors\n",
    "\n",
    "    def score_items(self, neighbors):\n",
    "        '''\n",
    "        Compute a set of scores for all items given a set of neighbors.\n",
    "        \n",
    "        Parameters\n",
    "        --------\n",
    "        neighbors: set of session ids\n",
    "        \n",
    "        Returns \n",
    "        --------\n",
    "        out : list of tuple (item, score)           \n",
    "        '''\n",
    "        # now we have the set of relevant items to make predictions\n",
    "        scores = dict()\n",
    "        # iterate over the sessions\n",
    "        for session in neighbors:\n",
    "            # get the items in this session\n",
    "            items = self.items_for_session(session[0])\n",
    "\n",
    "            for item in items:\n",
    "                old_score = scores.get(item)\n",
    "                new_score = session[1]\n",
    "\n",
    "                if old_score is None:\n",
    "                    scores.update({item: new_score})\n",
    "                else:\n",
    "                    new_score = old_score + new_score\n",
    "                    scores.update({item: new_score})\n",
    "\n",
    "        return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2790834a",
   "metadata": {
    "id": "1b3b17ab"
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "\n",
    "class ISeqRecommender(object):\n",
    "    \"\"\"Abstract Recommender class\"\"\"\n",
    "\n",
    "    logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "    logger = logging.getLogger()\n",
    "\n",
    "    def __init__(self):\n",
    "        super(ISeqRecommender, self).__init__()\n",
    "\n",
    "    def fit(self, train_data):\n",
    "        pass\n",
    "\n",
    "    def recommend(self, user_profile, user_id=None):\n",
    "        \"\"\"\n",
    "        Given the user profile return a list of recommendation\n",
    "        :param user_profile: the user profile as a list of item identifiers\n",
    "        :param user_id: (optional) the user id\n",
    "        :return: list of recommendations e.g. [([2], 0.875), ([6], 1.0)]\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    @staticmethod\n",
    "    def get_recommendation_list(recommendation):\n",
    "        return list(map(lambda x: x[0], recommendation))\n",
    "\n",
    "    @staticmethod\n",
    "    def get_recommendation_confidence_list(recommendation):\n",
    "        return list(map(lambda x: x[1], recommendation))\n",
    "\n",
    "    def activate_debug_print(self):\n",
    "        self.logger.setLevel(logging.DEBUG)\n",
    "\n",
    "    def deactivate_debug_print(self):\n",
    "        self.logger.setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed6b41bd",
   "metadata": {
    "id": "9e6ef755"
   },
   "outputs": [],
   "source": [
    "#KNNRecommender \n",
    "\n",
    "class KNNRecommender(ISeqRecommender):\n",
    "    \"\"\"\n",
    "    Interface to ItemKNN and Session-based KNN methods. Based on:\n",
    "    Evaluation of Session-based Recommendation Algorithms, Malte Ludewig and Dietmar Jannach\n",
    "    \"\"\"\n",
    "    knn_models = {\n",
    "        'sknn': SessionKNN\n",
    "    }\n",
    "\n",
    "    def __init__(self,\n",
    "                 model='cknn',\n",
    "                 **init_args):\n",
    "\n",
    "        super(KNNRecommender).__init__()\n",
    "        if model not in self.knn_models:\n",
    "            raise ValueError(\"Unknown KNN model '{}'. The available ones are: {}\".format(\n",
    "                model, list(self.knn_models.keys())\n",
    "            ))\n",
    "        self.init_args = init_args\n",
    "        self.init_args.update(dict(session_key='session_id',\n",
    "                                   item_key='item_id',\n",
    "                                   time_key='ts'))\n",
    "        self.model = self.knn_models[model](**self.init_args)\n",
    "        self.pseudo_session_id = 0\n",
    "\n",
    "    def __str__(self):\n",
    "        return str(self.model)\n",
    "\n",
    "    def fit(self, train_data):\n",
    "        self.logger.info('Converting training data to GRU4Rec format')\n",
    "        # parse training data to GRU4Rec format\n",
    "        train_data = dataset_to_gru4rec_format(dataset=train_data)\n",
    "\n",
    "        self.logger.info('Training started')\n",
    "        self.model.fit(train_data)\n",
    "        self.logger.info('Training completed')\n",
    "        self.pseudo_session_id = 0\n",
    "\n",
    "    def recommend(self, user_profile, user_id=None):\n",
    "        for item in user_profile:\n",
    "            pred = self.model.predict_next(session_id=self.pseudo_session_id,\n",
    "                                           input_item_id=item)\n",
    "        # sort items by predicted score\n",
    "        pred.sort_values(0, ascending=False, inplace=True)\n",
    "        # increase the psuedo-session id so that future call to recommend() won't be connected\n",
    "        self.pseudo_session_id += 1\n",
    "        # convert to the required output format\n",
    "        return [([x.index], x._2) for x in pred.reset_index().itertuples()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d7d4f72",
   "metadata": {
    "id": "5eecc340"
   },
   "outputs": [],
   "source": [
    "def dataset_to_gru4rec_format(dataset):\n",
    "    \"\"\"\n",
    "    Convert a list of sequences to GRU4Rec format.\n",
    "    Based on this StackOverflow answer: https://stackoverflow.com/a/48532692\n",
    "    :param dataset: the dataset to be transformed\n",
    "    \"\"\"\n",
    "\n",
    "    lst_col = 'sequence'\n",
    "    df = dataset.reset_index()\n",
    "    unstacked = pd.DataFrame({\n",
    "        col: np.repeat(df[col].values, df[lst_col].str.len()) for col in df.columns.drop(lst_col)}\n",
    "    ).assign(**{lst_col: np.concatenate(df[lst_col].values)})[df.columns]\n",
    "    # ensure that events in the session have increasing timestamps\n",
    "    unstacked['ts'] = unstacked['ts'] + unstacked.groupby('session_id').cumcount()\n",
    "    unstacked.rename(columns={'sequence': 'item_id'}, inplace=True)\n",
    "    return unstacked "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e361702",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "847158d3",
    "outputId": "34142c8d-531e-4c0d-b39b-95b7c499935e"
   },
   "outputs": [],
   "source": [
    "recommender = KNNRecommender(model='sknn', k=10)\n",
    "recommender.fit(training_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55c69c21",
   "metadata": {
    "id": "625f1a02"
   },
   "source": [
    "### Evaluation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b677d111",
   "metadata": {
    "id": "2a058d8b"
   },
   "outputs": [],
   "source": [
    "def precision(ground_truth, prediction):\n",
    "    \"\"\"\n",
    "    Compute Precision metric\n",
    "    :param ground_truth: the ground truth set or sequence\n",
    "    :param prediction: the predicted set or sequence\n",
    "    :return: the value of the metric\n",
    "    \"\"\"\n",
    "    ground_truth = remove_duplicates(ground_truth)\n",
    "    prediction = remove_duplicates(prediction)\n",
    "    precision_score = count_a_in_b_unique(prediction, ground_truth) / float(len(prediction))\n",
    "    assert 0 <= precision_score <= 1\n",
    "    return precision_score\n",
    "\n",
    "\n",
    "def recall(ground_truth, prediction):\n",
    "    \"\"\"\n",
    "    Compute Recall metric\n",
    "    :param ground_truth: the ground truth set or sequence\n",
    "    :param prediction: the predicted set or sequence\n",
    "    :return: the value of the metric\n",
    "    \"\"\"\n",
    "    ground_truth = remove_duplicates(ground_truth)\n",
    "    prediction = remove_duplicates(prediction)\n",
    "    recall_score = 0 if len(prediction) == 0 else count_a_in_b_unique(prediction, ground_truth) / float(\n",
    "        len(ground_truth))\n",
    "    assert 0 <= recall_score <= 1\n",
    "    return recall_score\n",
    "\n",
    "\n",
    "def mrr(ground_truth, prediction):\n",
    "    \"\"\"\n",
    "    Compute Mean Reciprocal Rank metric. Reciprocal Rank is set 0 if no predicted item is in contained the ground truth.\n",
    "    :param ground_truth: the ground truth set or sequence\n",
    "    :param prediction: the predicted set or sequence\n",
    "    :return: the value of the metric\n",
    "    \"\"\"\n",
    "    rr = 0.\n",
    "    for rank, p in enumerate(prediction):\n",
    "        if p in ground_truth:\n",
    "            rr = 1. / (rank + 1)\n",
    "            break\n",
    "    return rr\n",
    "\n",
    "def count_a_in_b_unique(a, b):\n",
    "    \"\"\"\n",
    "    :param a: list of lists\n",
    "    :param b: list of lists\n",
    "    :return: number of elements of a in b\n",
    "    \"\"\"\n",
    "    count = 0\n",
    "    for el in a:\n",
    "        if el in b:\n",
    "            count += 1\n",
    "    return count\n",
    "\n",
    "def remove_duplicates(l):\n",
    "    return [list(x) for x in set(tuple(x) for x in l)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f25e335",
   "metadata": {
    "id": "fa2c71e1"
   },
   "outputs": [],
   "source": [
    "METRICS = {'precision':precision, \n",
    "           'recall':recall,\n",
    "           'mrr': mrr}\n",
    "TOPN = 10 # length of the recommendation list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd04129b",
   "metadata": {
    "id": "25a926ff"
   },
   "outputs": [],
   "source": [
    "GIVEN_K = 1\n",
    "LOOK_AHEAD = 1\n",
    "STEP = 1\n",
    "topn_list = [1, 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4831991d",
   "metadata": {
    "id": "62210f68"
   },
   "outputs": [],
   "source": [
    "#get test sequence \n",
    "def get_test_sequences(test_data, given_k):\n",
    "    # we can run evaluation only over sequences longer than abs(LAST_K)\n",
    "    #given_k -> number of events from the initial sequence that will assigned to the user profile\n",
    "    test_sequences = test_data.loc[test_data['sequence'].map(len) > abs(given_k), 'sequence'].values\n",
    "    return test_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a660204b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f63dac55",
    "outputId": "5de76337-046e-4450-89b6-b370f08f05a0"
   },
   "outputs": [],
   "source": [
    "# ensure that all sequences have the same minimum length \n",
    "test_sequences = get_test_sequences(test_data, GIVEN_K)\n",
    "print('{} sequences available for evaluation'.format(len(test_sequences)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "902c11e9",
   "metadata": {
    "id": "637baac9"
   },
   "outputs": [],
   "source": [
    "def sequential_evaluation(recommender,\n",
    "                          test_sequences,\n",
    "                          evaluation_functions,\n",
    "                          users=None,\n",
    "                          given_k=1,\n",
    "                          look_ahead=1,\n",
    "                          top_n=10,\n",
    "                          scroll=True,\n",
    "                          step=1):\n",
    "    \"\"\"\n",
    "    Runs sequential evaluation of a recommender over a set of test sequences\n",
    "    :param recommender: the instance of the recommender to test\n",
    "    :param test_sequences: the set of test sequences\n",
    "    :param evaluation_functions: list of evaluation metric functions\n",
    "    :param users: (optional) the list of user ids associated to each test sequence. Required by personalized models like FPMC.\n",
    "    :param given_k: (optional) the initial size of each user profile, starting from the first interaction in the sequence.\n",
    "                    If <0, start counting from the end of the sequence. It must be != 0.\n",
    "    :param look_ahead: (optional) number of subsequent interactions in the sequence to be considered as ground truth.\n",
    "                    It can be any positive number or 'all' to extend the ground truth until the end of the sequence.\n",
    "    :param top_n: (optional) size of the recommendation list\n",
    "    :param scroll: (optional) whether to scroll the ground truth until the end of the sequence.\n",
    "                If True, expand the user profile and move the ground truth forward of `step` interactions. Recompute and evaluate recommendations every time.\n",
    "                If False, evaluate recommendations once per sequence without expanding the user profile.\n",
    "    :param step: (optional) number of interactions that will be added to the user profile at each step of the sequential evaluation.\n",
    "    :return: the list of the average values for each evaluation metric\n",
    "    \"\"\"\n",
    "    if given_k == 0:\n",
    "        raise ValueError('given_k must be != 0')\n",
    "\n",
    "    metrics = np.zeros(len(evaluation_functions))\n",
    "    with tqdm(total=len(test_sequences)) as pbar:\n",
    "        for i, test_seq in enumerate(test_sequences):\n",
    "            if users is not None:\n",
    "                user = users[i]\n",
    "            else:\n",
    "                user = None\n",
    "            if scroll:\n",
    "                metrics += sequence_sequential_evaluation(recommender,\n",
    "                                                          test_seq,\n",
    "                                                          evaluation_functions,\n",
    "                                                          user,\n",
    "                                                          given_k,\n",
    "                                                          look_ahead,\n",
    "                                                          top_n,\n",
    "                                                          step)\n",
    "            else:\n",
    "                metrics += evaluate_sequence(recommender,\n",
    "                                             test_seq,\n",
    "                                             evaluation_functions,\n",
    "                                             user,\n",
    "                                             given_k,\n",
    "                                             look_ahead,\n",
    "                                             top_n)\n",
    "            pbar.update(1)\n",
    "    return metrics / len(test_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e0c84af",
   "metadata": {
    "id": "b2ca36d4"
   },
   "outputs": [],
   "source": [
    "def sequence_sequential_evaluation(recommender, seq, evaluation_functions, user, given_k, look_ahead, top_n, step):\n",
    "    if given_k < 0:\n",
    "        given_k = len(seq) + given_k\n",
    "\n",
    "    eval_res = 0.0\n",
    "    eval_cnt = 0\n",
    "    for gk in range(given_k, len(seq), step):\n",
    "        eval_res += evaluate_sequence(recommender, seq, evaluation_functions, user, gk, look_ahead, top_n)\n",
    "        eval_cnt += 1\n",
    "    return eval_res / eval_cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "812ec922",
   "metadata": {
    "id": "0b72c55a"
   },
   "outputs": [],
   "source": [
    "def evaluate_sequence(recommender, seq, evaluation_functions, user, given_k, look_ahead, top_n):\n",
    "    \"\"\"\n",
    "    :param recommender: which recommender to use\n",
    "    :param seq: the user_profile/ context\n",
    "    :param given_k: last element used as ground truth. NB if <0 it is interpreted as first elements to keep\n",
    "    :param evaluation_functions: which function to use to evaluate the rec performance\n",
    "    :param look_ahead: number of elements in ground truth to consider. if look_ahead = 'all' then all the ground_truth sequence is considered\n",
    "    :return: performance of recommender\n",
    "    \"\"\"\n",
    "    # safety checks\n",
    "    if given_k < 0:\n",
    "        given_k = len(seq) + given_k\n",
    "\n",
    "    user_profile = seq[:given_k]\n",
    "    ground_truth = seq[given_k:]\n",
    "\n",
    "    # restrict ground truth to look_ahead\n",
    "    ground_truth = ground_truth[:look_ahead] if look_ahead != 'all' else ground_truth\n",
    "    ground_truth = list(map(lambda x: [x], ground_truth))  # list of list format\n",
    "\n",
    "    if not user_profile or not ground_truth:\n",
    "        # if any of the two missing all evaluation functions are 0\n",
    "        return np.zeros(len(evaluation_functions))\n",
    "\n",
    "    r = recommender.recommend(user_profile, user)[:top_n]\n",
    "\n",
    "    if not r:\n",
    "        # no recommendation found\n",
    "        return np.zeros(len(evaluation_functions))\n",
    "    reco_list = recommender.get_recommendation_list(r)\n",
    "\n",
    "    tmp_results = []\n",
    "    for f in evaluation_functions:\n",
    "        tmp_results.append(f(ground_truth, reco_list))\n",
    "    return np.array(tmp_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0d3ef58",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 462
    },
    "id": "a269e333",
    "outputId": "afb00bf4-aaef-4e74-d6ad-ff336008dd2c"
   },
   "outputs": [],
   "source": [
    "res_list = []\n",
    "\n",
    "for topn in topn_list:\n",
    "    print('Evaluating recommendation lists with length: {}'.format(topn))\n",
    "    res_tmp = sequential_evaluation(recommender,\n",
    "                                    test_sequences=test_sequences,\n",
    "                                    given_k=GIVEN_K,\n",
    "                                    look_ahead=LOOK_AHEAD,\n",
    "                                    evaluation_functions=METRICS.values(),\n",
    "                                    top_n=topn,\n",
    "                                    scroll=True,  # here we average over all profile lengths\n",
    "                                    step=STEP)\n",
    "    mvalues = list(zip(METRICS.keys(), res_tmp))\n",
    "    res_list.append((topn, mvalues))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eb39904",
   "metadata": {
    "id": "af697525"
   },
   "outputs": [],
   "source": [
    "# show separate plots per metric\n",
    "fig, axes = plt.subplots(nrows=1, ncols=len(METRICS), figsize=(15,5))\n",
    "res_list_t = list(zip(*res_list))\n",
    "for midx, metric in enumerate(METRICS):\n",
    "    mvalues = [res_list_t[1][j][midx][1] for j in range(len(res_list_t[1]))]\n",
    "    ax = axes[midx]\n",
    "    ax.plot(topn_list, mvalues)\n",
    "    ax.set_title(metric)\n",
    "    ax.set_xticks(topn_list)\n",
    "    ax.set_xlabel('List length')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6bdf1ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a91dd050",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ea72cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(res_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6898084b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('res_list4may.txt', 'w') as f:\n",
    "    f.write(json.dumps(res_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bbcc1a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f0bea35",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "res_tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53f90089",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_tmp1 = list(res_tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b32c97ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('res_tmp_4may.txt', 'w') as f:\n",
    "    f.write(json.dumps(res_tmp1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e74986c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('hhh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62bd0453",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d7f265f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "machine_shape": "hm",
   "name": "SessionKNN_Model_2 (try).ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
